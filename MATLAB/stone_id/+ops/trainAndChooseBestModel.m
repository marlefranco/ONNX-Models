function [results, info, session] = trainAndChooseBestModel(dataTrain, splitIdx)

%% Initialize parameters to run trials over
dataParameters = optimizeParameter.empty(0,1);
modelParameters = optimizeParameter.empty(0,1);

% % Data parameters 
dataParameters(1) = optimizeParameter.new(...
    "Name", "Normalization", ...
    "Range", ["none"], ...
    "Type", "Discrete");

dataParameters(2) = optimizeParameter.new(...
    "Name", "FeatureSelection", ...
    "Range", ["none", "fscchi2", "pca"], ...
    "Type", "Set");

dataParameters(3) = optimizeParameter.new(...
    "Name", "FeatureExtraction", ...
    "Range", ["none"], ...
    "Type", "Set");

% Model Parameters
modelParameters(1) = optimizeParameter.new(...
    "Name", "KFold", ...
    "Range", 5,...
    "Type", "Discrete");

modelParameters(2) = optimizeParameter.new(...
    "Name", "Learners", ...
    "Range", {["tree", "knn",  "svm", ...
     "ecoc", "ensemble", "discr"]},...
    "Type", "Set");
% 
% %}
% dataParameters(1) = optimizeParameter.new(...
%     "Name", "Normalization", ...
%     "Range", ["none"], ...
%     "Type", "Discrete");
% 
% dataParameters(2) = optimizeParameter.new(...
%     "Name", "FeatureSelection", ...
%     "Range", ["none"], ...
%     "Type", "Set");
% 
% dataParameters(3) = optimizeParameter.new(...
%     "Name", "FeatureExtraction", ...
%     "Range", ["none"], ...
%     "Type", "Set");
% % Model Parameters
% modelParameters(1) = optimizeParameter.new(...
%     "Name", "KFold", ...
%     "Range", 5,...
%     "Type", "Discrete");
% 
% modelParameters(2) = optimizeParameter.new(...
%     "Name", "Learners", ...
%     "Range", {["knn",  "svm", ...
%      "ecoc"]},...
%     "Type", "Set");

modelParameters(3) = optimizeParameter.new(...
    "Name", "HyperparameterOptimizationOptions",...
    "Range", {struct('MaxObjectiveEvaluations', 30, 'UseParallel', true)},...
    "Type", "Set");

%% Initialize session

session = experiment.Classification( ...
    "Data", dataTrain, ...
    "Model", "automl", ...
    "DataFcn", @(x, settings)basePipelineTrain(x, "TrainIndices", splitIdx{1}, ...
    settings{:}), ...
    "DataConfiguration", dataParameters, ...
    "ModelConfiguration", modelParameters, ...
    "Search", "gridsearch", ...
    "NumGridDivisions", 2, ...
    "UseParallel", false);

%% Run session
session.validate();
session.build();
session.preview();
session.run();

%% Evaluate session
% evalT = session.describe();
% evalT = [evalT(:,1:9) evalT(:,14) evalT(:,10:13) evalT(:,15:18)];

%% Overwrite test data evaluation results
sessionResults = session.describe();
dataTest = dataTrain(splitIdx{2},:);

    for i = 1:height(sessionResults)
       % try
            [results, ~] = session.select(sessionResults.Item(i), "Metadata", true);
            dataPred = basePipelinePredict( results.mdl, dataTest, results.pipelinesweep{:});
            [precisionOnTest, recallOnTest, f1ScoreOnTest, AUCOnTest] = ...
                fitc.computeMetrics( dataPred.Response, dataPred.Prediction, ...
                dataPred.Scores{:,:}, dataPred.Scores.Properties.VariableNames );
            sessionResults.precisionOnTest(i,:) = precisionOnTest;
            sessionResults.recallOnTest(i,:) = recallOnTest;
            sessionResults.f1ScoreOnTest(i,:) = f1ScoreOnTest;
            sessionResults.AUCOnTest(i,:) = AUCOnTest;
            sessionResults.errorOnTest(i) = ...
                nnz(dataPred.Response~=dataPred.Prediction)/height(dataPred);
%         catch
%             continue;
%         end
    end



%% Extract session results
sessionResults = sortrows(sessionResults, "errorOnTest");
% sessionResults = [sessionResults(:,1:2), sessionResults(:,[8,9,14]), ...
%     sessionResults(:,3:7), sessionResults(:,[10:13,15:18])];

% choose model with minimum accuracy difference from the top 10 models
% [~,sortIdx] = sort(abs(sessionResults.errorOnCV - sessionResults.errorOnTest), "ascend");
% iD = find(sortIdx<=10, 1); 
[results, info] = session.select(sessionResults.Item(1), "Metadata", true);

end